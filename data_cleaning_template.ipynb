{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d8e35ed-56c1-4fc4-bf52-f39a9e186ead",
   "metadata": {},
   "source": [
    "<font size=\"6\">Data Cleaning Workflow</font>\n",
    "<br> \n",
    "<br>\n",
    "<font size=\"3\">This data cleaning template uses python commands to convert CSV files to SQL database tables. It runs through basic cleaning of CSV data files and prints cleaned CSV files back to your project folder. To run, replace file and project paths, database_name, and table_name.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19edd41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install ipython-sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7defe5d-8533-4174-ae6a-a9588ed033b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbf0127-d326-4527-a8d6-ade256933120",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c42bc1-f613-4361-a899-10df401b988f",
   "metadata": {},
   "source": [
    "<font size=\"6\">Data Preparation</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9743842",
   "metadata": {},
   "source": [
    "<font size=\"3\">Convert CSV file(s) to SQL table(s) within database. Replace file and project paths, database_name, and table_name</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f934def",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory containing your CSV files\n",
    "csv_directory = '/Path/to/CSV/File'\n",
    "\n",
    "# SQLite database file\n",
    "db_file = 'database_name.db'\n",
    "\n",
    "# Create a SQLite database connection\n",
    "conn = sqlite3.connect(db_file)\n",
    "\n",
    "# Iterate through CSV files in the directory\n",
    "for csv_file in os.listdir(csv_directory):\n",
    "    if csv_file.endswith('.csv'):\n",
    "        file_path = os.path.join(csv_directory, csv_file)\n",
    "        \n",
    "        # Read the CSV file into a DataFrame\n",
    "        df = pd.read_csv(file_path, encoding='latin1')\n",
    "        \n",
    "        # Replace spaces and special characters in column names with underscores\n",
    "        df.columns = [c.replace(' ', '_').replace('.', '_').replace('-', '_') for c in df.columns]\n",
    "        \n",
    "        # Determine the table name (use the file name without extension)\n",
    "        table_name = os.path.splitext(csv_file)[0]\n",
    "        \n",
    "        # Write the DataFrame to the SQLite database as a new table\n",
    "        df.to_sql(table_name, conn, if_exists='replace', index=False)\n",
    "\n",
    "# Commit changes and close the database connection\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1b08b7-421f-42fd-8782-47e66fc16c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to project database\n",
    "%sql sqlite:///database_name.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd901d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that table was converted from csv and pulled into project database\n",
    "conn = sqlite3.connect('database_name.db')\n",
    "query = \"\"\"\n",
    "    SELECT \n",
    "        name \n",
    "    FROM sqlite_master \n",
    "    WHERE type='table';\n",
    "\"\"\"\n",
    "result = pd.read_sql_query(query, conn)\n",
    "print(tabulate(result, headers='keys', tablefmt='psql', showindex=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840ccb79",
   "metadata": {},
   "source": [
    "<font size=\"3\">**Optional:** Cleanup database by removing unwanted tables</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e4e3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean up project database\n",
    "conn = sqlite3.connect('database_name.db')\n",
    "\n",
    "cursor = conn.cursor()\n",
    "table_name_to_remove = 'unwanted_table_name'\n",
    "\n",
    "drop_table_query = f\"DROP TABLE IF EXISTS {table_name_to_remove};\"\n",
    "cursor.execute(drop_table_query)\n",
    "\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500ec913-dfd4-47c2-8f23-8699c4730358",
   "metadata": {},
   "source": [
    "<font size=\"6\">Preview Tables</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d0f5d3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Confirm data types are correct\n",
    "conn = sqlite3.connect('database_name.db')\n",
    "query = \"\"\"\n",
    "    PRAGMA table_info(table_name)\n",
    "\"\"\"\n",
    "result = pd.read_sql_query(query, conn)\n",
    "print(tabulate(result, headers='keys', tablefmt='psql', showindex=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bb7b86",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Get preview of project table\n",
    "pd.set_option('display.max_columns',None)\n",
    "table_name = pd.read_csv('/Path/to/CSV/File/file_name.csv', encoding='latin1')\n",
    "table_name.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbae13f",
   "metadata": {},
   "source": [
    "<font size=\"6\">Data Cleaning</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29498f0",
   "metadata": {},
   "source": [
    "<font size=\"3\">Find duplicates and missing values</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e8b36b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check for duplicates in the entire table\n",
    "duplicate_rows = table_name[table_name.duplicated()]\n",
    "if duplicate_rows.empty:\n",
    "    print(\"No duplicate rows found.\")\n",
    "else:\n",
    "    print(\"Duplicate Rows:\")\n",
    "    print(duplicate_rows)\n",
    "    \n",
    "# Check for missing values in the entire table\n",
    "nan_values = table_name.isna().sum()\n",
    "if nan_values.sum() == 0:\n",
    "    print(\"No missing values found.\")\n",
    "else:\n",
    "    print(\"NaN (Missing Values) Count:\")\n",
    "    print(nan_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115f8ca1",
   "metadata": {},
   "source": [
    "<font size=\"3\">Remove duplicate rows and replace missing values</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803af7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If there are duplicates, remove duplicate rows based on all columns\n",
    "table_name_clean = table_name.drop_duplicates()\n",
    "\n",
    "# If no duplicates, start here. Replace blank cells with 0 in specific columns. \n",
    "table_name_clean = table_name[\"column1\"].fillna(0, inplace=True)\n",
    "\n",
    "# Replace blank cells with \"not given\" in specific column.\n",
    "table_name_clean = table_name[\"column2\"].fillna(\"not given\", inplace=True)\n",
    "\n",
    "# Check for missing values in the entire table\n",
    "nan_values = table_name_clean.isna().sum()\n",
    "if nan_values.sum() == 0:\n",
    "    print(\"No missing values found.\")\n",
    "else:\n",
    "    print(\"NaN (Missing Values) Count:\")\n",
    "    print(nan_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adadaea7",
   "metadata": {},
   "source": [
    "<font size=\"3\">Remove whitespace</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58d4f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in table_name.columns:\n",
    "    # Check if the column contains strings (object dtype)\n",
    "    if table_name[column].dtype == 'object':\n",
    "        # Strip leading and trailing whitespace from string values\n",
    "        table_name[column] = table_name[column].str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942372ea",
   "metadata": {},
   "source": [
    "<font size=\"3\">Rename Columns</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ee9489",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "table_name_clean.rename(columns={\"column_name\":\"renamed_column\",\"column_name2\": \"renamed_column2\"}, inplace=True)\n",
    "print(table_name_clean.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6228ec",
   "metadata": {},
   "source": [
    "<font size=\"3\">Concatenate columns and convert to different data type</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de32e67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate multiple columns into a single string column with delimiter\n",
    "table_name_clean['new_column'] = table_name_clean['column1'].astype(str) + '[delimiter]' + table_name['column2'].astype(str)\n",
    "\n",
    "# Convert the concatenated column to different data type format\n",
    "table_name_clean['new_column'] = pd.to_[datatype](table_name_clean['new_colun'], format='%m/%d/%Y')\n",
    "\n",
    "# Drop the individual component columns if needed\n",
    "table_name_clean.drop(columns=['column1', 'column2'], inplace=True)\n",
    "\n",
    "table_name_clean.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3267e4",
   "metadata": {},
   "source": [
    "<font size=\"3\">Apply proper case</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83868d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the title case transformation to column1\n",
    "table_name_clean['column1'] = table_name_clean['column1'].str.title()\n",
    "\n",
    "table_name_clean.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e160e45",
   "metadata": {},
   "source": [
    "<font size=\"3\">Split column with multiple parts and reorder</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae825ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the maximum number of parts in the column with multiple parts. Add 1 to account for columns with only 1 part\n",
    "max_parts = table_name_clean['column with mult. parts'].str.count(',') + 1 \n",
    "\n",
    "# Determine the maximum number of parts\n",
    "max_n = max_parts.max()\n",
    "\n",
    "# Split the new_column by comma and expand it into separate columns\n",
    "split_columns = [f'new_column{i}' for i in range(1, max_n + 1)]\n",
    "split_artists = table_name_clean['new_column'].str.split(',', expand=True, n=max_n)\n",
    "split_artists.columns = split_columns\n",
    "\n",
    "# Drop the original column if you don't need it anymore\n",
    "table_name_clean.drop(columns=['column with mult. parts'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899d6de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(table_name_clean.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618f6e94",
   "metadata": {},
   "source": [
    "<font size=\"3\">Reorder columns</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2477aed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#List new column names in desired order\n",
    "column_order = ['column1', 'column2', 'column3']\n",
    "table_name_clean = table_name_clean[column_order]\n",
    "\n",
    "table_name_clean.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801c0f78",
   "metadata": {},
   "source": [
    "<font size=\"3\">Remove non-character symbols from strings</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8516e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Remove symbols from column1\n",
    "table_name_clean['column1'] = table_name_clean['column1'].str.replace('[^a-zA-Z0-9\\s]', '', regex=True)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "table_name_clean.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f083cc2",
   "metadata": {},
   "source": [
    "<font size=\"3\">Print cleaned table to CSV</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc491e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path where you want to save the CSV file\n",
    "csv_file_path = '/Path/to/CSV/File/table_name_clean.csv'\n",
    "\n",
    "# Save the DataFrame to the CSV file\n",
    "table_name_clean.to_csv(csv_file_path, index=False)\n",
    "\n",
    "# Print a message to confirm the file has been saved\n",
    "print(f\"DataFrame saved to {csv_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1ecb67",
   "metadata": {},
   "source": [
    "<font size=\"2\">All data for this project was acquired through Ref. \"[Database]\"</font>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
